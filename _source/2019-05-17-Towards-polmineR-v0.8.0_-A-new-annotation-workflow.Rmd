---
layout: post
title:  "Towards polmineR v0.8.0: An annotation workflow "
date:   2019-05-17
author: Andreas Bl√§tte
categories: Posts
tags: news
---

# Towards polmineR v0.8.0: An annotation workflow

A driving idea behind the polmineR package is to offer the basic vocabulary to implement workflows for complex text analytical tasks, including annotation. The basic design necessary to do so, i.e. the ability to reconstruct (passages of) full text at any time has always been there, but the annotation functionality has been an unfullfilled promised. As we are approaching v0.8.0, the idea to realize an annotation workflow shall finally materialize.

In this blog post, I would like to introduce the new workflow to annotate classes inheriting from the `textstat` class, such as a `kwic` analysis or `cooccurrences`. It is available in its current form starting from polmineR version 0.7.11.9023, available on the dev branch of the polmineR git repo at GitHub. It can be installed as follows (if you have the devtools package installed):

```{r, eval = FALSE}
devtools::install_github("PolMine/polmineR")
```

The impetus for developing the functionality came from using a dictionary to score the degree of populism in  parliamentary speeches. The validity of measurements using dictionaries can not always be taken for granted, given the ambiguity of the usage of terms, and the aim was to have a simple and efficient workflow that works without having to leave the R session used for the basic corpus analysis.

The scenario I use here is a simple effort to disambiguate (the German word) "Integration". Very often, it is used to refer to the integration of immigrants into society, and let us assume we want to count the number of occurrences of "Integration" in the context of migration and integration affairs, and that we want to avoid counting the occurrence of "Integration" in other contexts. This disambiguation might also be achieved through a rule-based procedure (i.e. a dictionary of words required to occurr in the neighborhood of our match, and/or a dictionary preventing a match to be counted), or a procedure based on training data. But develop both approaches, manual annotation is a necessary first step. So this is why we need a workflow for manual annotation that works. After all, once we have it, we can also use it for a brute-force manual annotation from dusk till dawn for all matches without further sophistication. At times, this appraoch may not be the worst one from the "know your data" and validity point of view.

The solution polmineR is now able to offer is a [shiny gadget](https://www.rstudio.com/resources/webinars/shiny-gadgets-interactive-tools/) that uses the [Handsontable](https://handsontable.com/) JavaScript library as exposed through the [rhandsontable](https://jrowen.github.io/rhandsontable/) package. When you start the gadget in an RStudio session, it will be shown in the Viewer pane of RStudio, and you will have the results of your annotation exercise in the R sessions right away, without having to export data and switching applications.

So this is how you use this new functionality. We start by loading polmineR and activating the GERMAPARL corpus of parliamentary debates in the German Bundestag. 

```{r message = FALSE}
library(polmineR)
use("GermaParl") # activate GERMAPARL corpus
```

Then we generagte a `kwic` object using the `kwic()`-method. Working on the scenario introduced before, we look up matches for "Integration" in the GERMAPARL corpus.

```{r}
x <- kwic("GERMAPARL", query = "Integration")
```

The resulting object x has used the default left and right context of 5 tokens. Often, we will find that we may want to see more words to solidify our annotation decisions. For this, we use a new argument of the `enrich()`-method to get us an extra 15 words to the left and to the right of our search windows.

```{r}
x <- enrich(x, extra = 15)
```

When `kwic` objects are generated and enriched, a `data.table` in the slot `stat` of the object is filled with the concordance lines. This table can be augmented with a new column as follows. In our example, we add a column called "mi" (for migration and integration) to indicate whether our match for "Integration" occurrs in a migration and integration context.

```{r}
annotations(x) <- list(name = "mi", what = TRUE)
```

Note that you can also add columns with a character vector, or a factor. Assigning a factor can be a good choice, when you want to offer users or yourself a limited set of choices. One of the beauties of basing the shiny widget on the `Handsontable` library for html spreadsheets is that for factor columns, a drop down menu is used for data input by default. See the examples for the annotation functionality (`?annotations`) to see an example.

Now we have a kwic object with an annotation layer. We can use the `edit()` method to call the shiny gadget we have been talking about.

```{r, eval = FALSE}
edit(x)
```

Once you finished editing annotations, click the "Done"-button, and the results of the annotation effort are available in the R session. You can get the `data.table` with the annotations by calling the `annotations()`-method on the annotated object.


```{r, eval = FALSE}
annotations(x)
```

And of course, you can aggregate the result. For instance, to count the number of TRUE/FALSE classifications, use the notation of the `data.table`-package to aggregate results for the column "mi".

```{r, eval = FALSE}
annotations(x)[, .N, by = mi]
```

Having gone through our `kwic` object, the real work in our analysis to obtain a substantive result may be assumed. If the aim was do get rid of false matches, use the `subset()`-method on the `kwic` object to discard the matches we have annotated with FALSE.

```{r}
x_min <- subset(x, mi == TRUE)
length(x_min) # see the length of the shortened object
```

Quite obviously, it may be tedious to go through concordances if we have a large number of matches, and of course, it may be very attractive to use a limited set of annotated lines as training data. For most ML exercises, we will need a Document-Term-Matrix. Get it as follows...

```{r}
dtm <- as.DocumentTermMatrix(x, p_attribute = "word")
```

And we have the labels for the algorithm at hand, we can get it by calling `annotations()`. But explaining how to do the machine learning part goes beyond this post: The aim here has been to introduce the new annotation workflow of the polmineR packge

Just a final remark: You can annotate and edit any object that inherits from the `textstat`-class. Apart from annotating `kwic`-objects, annotating `cooccurrences` may be an important use case. I hope you find the new annotation functionality useful. Enjoy! Feedback is welcome!

Thanks to Christoph Leonhardt.